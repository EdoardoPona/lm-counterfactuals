{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f979492d-4508-461a-8e76-4f559ccb7e17",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nnsight is not detected. Please install via 'pip install nnsight' for nnsight backend.\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "from transformers.generation.logits_process import LogitsProcessor,LogitsProcessorList\n",
    "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
    "import numpy as np\n",
    "from scipy.stats import gumbel_l\n",
    "#from arsenal.maths.rvs import TruncatedDistribution\n",
    "import copy\n",
    "import os\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0\" \n",
    "import torch\n",
    "import tqdm\n",
    "import scipy\n",
    "\n",
    "from scipy.stats import gumbel_l, gumbel_r\n",
    "#from arsenal.maths.rvs import TruncatedDistribution\n",
    "import transformers\n",
    "from evaluate import load\n",
    "import pickle\n",
    "from collections import Counter, defaultdict\n",
    "import ot\n",
    "import sk2torch\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "# import nn\n",
    "import torch.nn as nn\n",
    "import copy\n",
    "import pyreft"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3ce370e7-fcb8-4e20-bbae-9e331410f049",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tue Sep 17 22:58:01 2024       \n",
      "+---------------------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 535.183.06             Driver Version: 535.183.06   CUDA Version: 12.2     |\n",
      "|-----------------------------------------+----------------------+----------------------+\n",
      "| GPU  Name                 Persistence-M | Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp   Perf          Pwr:Usage/Cap |         Memory-Usage | GPU-Util  Compute M. |\n",
      "|                                         |                      |               MIG M. |\n",
      "|=========================================+======================+======================|\n",
      "|   0  Tesla V100-SXM2-32GB           On  | 00000000:16:00.0 Off |                    0 |\n",
      "| N/A   42C    P0              43W / 300W |      0MiB / 32768MiB |      0%      Default |\n",
      "|                                         |                      |                  N/A |\n",
      "+-----------------------------------------+----------------------+----------------------+\n",
      "|   1  Tesla V100-SXM2-32GB           On  | 00000000:89:00.0 Off |                    0 |\n",
      "| N/A   31C    P0              39W / 300W |      0MiB / 32768MiB |      0%      Default |\n",
      "|                                         |                      |                  N/A |\n",
      "+-----------------------------------------+----------------------+----------------------+\n",
      "                                                                                         \n",
      "+---------------------------------------------------------------------------------------+\n",
      "| Processes:                                                                            |\n",
      "|  GPU   GI   CI        PID   Type   Process name                            GPU Memory |\n",
      "|        ID   ID                                                             Usage      |\n",
      "|=======================================================================================|\n",
      "|  No running processes found                                                           |\n",
      "+---------------------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d7241b8-ea02-436f-afff-27556e247208",
   "metadata": {},
   "source": [
    "## data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "48394cbd-5747-426f-abb0-a6dc458596cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"bios_data/bios_train.pickle\", \"rb\") as f:\n",
    "    data = pickle.load(f)\n",
    "    y = np.array([d[\"p\"] for d in data])\n",
    "    z = np.array([1 if d[\"g\"] == \"m\" else 0 for d in data])\n",
    "    texts = [d[\"text\"] for d in data]\n",
    "\n",
    "y_to_keep = [\"professor\"]\n",
    "idx_to_keep = [i for i in range(len(y)) if y[i] in y_to_keep]\n",
    "y = y[idx_to_keep]\n",
    "z = z[idx_to_keep]\n",
    "texts = [texts[i] for i in idx_to_keep]\n",
    "\n",
    "num_m, num_f = sum(z), len(z) - sum(z)\n",
    "n = 10000#min(num_m, num_f)\n",
    "idx_m = [i for i in range(len(z)) if z[i] == 1]\n",
    "idx_f = [i for i in range(len(z)) if z[i] == 0]\n",
    "idx = idx_m[:n] + idx_f[:n]\n",
    "y = y[idx]\n",
    "z = z[idx]\n",
    "texts = [texts[i] for i in idx]\n",
    "texts_female = [t for i,t in enumerate(texts) if z[i] == 0][:100]\n",
    "\n",
    "from datasets import load_dataset\n",
    "\n",
    "ds = load_dataset(\"facebook/md_gender_bias\", name=\"new_data\")\n",
    "idx = [x[0] for x in ds[\"train\"][\"labels\"]]\n",
    "texts_original = [x for i,x in enumerate(ds[\"train\"][\"original\"]) if idx[i] in [1,3]] \n",
    "texts_target = [x for i,x in enumerate(ds[\"train\"][\"text\"]) if idx[i] in [1,3]] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c497e04b-9a41-4735-aab2-d086fe637006",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Janice Nesser is an Associate Professor Art at STLCC-Florissant Valley. She serves as the Chair of the Art & Humanities Department and as the Interim Dean of Liberal Arts. She is the former Photography Program Coordinator.',\n",
       " '~Dr. Keri L. Colabroy is an Associate Professor of Chemistry at Muhlenberg College. She engages undergraduates in research in the teaching lab and through independent study investigating enzymes in bacterial natural product biosynthesis.',\n",
       " 'Kelly Olson is an associate professor at the William H. Bowen School of Law at UALR. She directs the mediation clinic at the school, as well as being a state-certified mediator herself. She thinks the decline in the number of jury trials is both good and bad.',\n",
       " \"Petra Fachinger is an associate professor of German at Queen's University. Her research interests include: German Literature and Film after 1968, The Holocaust in Literature and Film, Turkish German Literature and Film, Postwar German Jewish Literature. S ...\",\n",
       " 'Diane Meyer is an Associate Professor of Photography at Loyola Marymount University and resides in Santa Monica. She received her BFA in Photography from New York University, Tisch School of the Arts in 1999 and an MFA in Visual Arts from The University of California, San Diego in 2002.']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(sorted(texts_female, key = lambda x: len(x)))[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "469c285c-f1e5-4266-a4f7-f5c1f0fae54a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "ad90b24e-4619-49ce-b8c1-abefeedd4bef",
   "metadata": {},
   "source": [
    "## Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c8c77dfd-8031-4d38-a02d-a1dc10f7bce4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/cluster/home/sravfogel/venv/lib/python3.12/site-packages/huggingface_hub/file_download.py:1150: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d1fdef61af414dbe95e31bea6936abe2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from transformers import BitsAndBytesConfig\n",
    "\n",
    "model_name_or_path = \"meta-llama/Llama-2-7b-chat-hf\"\n",
    "\n",
    "# get tokenizer\n",
    "tokenizer = transformers.AutoTokenizer.from_pretrained(\n",
    "    model_name_or_path, model_max_length=2048, \n",
    "    padding_side=\"right\", use_fast=False)\n",
    "tokenizer.pad_token = tokenizer.unk_token\n",
    "\n",
    "\n",
    "counterfactual_model = transformers.AutoModelForCausalLM.from_pretrained(\n",
    "    model_name_or_path, torch_dtype=torch.bfloat16, device_map=\"cuda:0\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1fedac85-6279-44ea-95cd-b518e2fe549b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda', index=0)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "counterfactual_model.device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3ddff7a9-3f48-430c-9aa7-df7770f6c3df",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d027ce4feb0b48f685049d93b260dfe6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "original_model = transformers.AutoModelForCausalLM.from_pretrained(\n",
    "    model_name_or_path, torch_dtype=torch.bfloat16, device_map=\"cuda:0\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d358e7a9-ccfd-462e-9efb-7727587ec7af",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trainable intervention params: 16,386 || trainable model params: 0\n",
      "model params: 6,738,415,616 || trainable%: 0.00024317289009440643\n"
     ]
    }
   ],
   "source": [
    "prompt_no_input_template = \"\"\"<s>[INST] <<SYS>>\n",
    "You are a helpful assistant.\n",
    "<</SYS>>\n",
    "%s [/INST]\n",
    "\"\"\"\n",
    "\n",
    "# get reft model\n",
    "reft_config = pyreft.ReftConfig(representations={\n",
    "    \"layer\": 15, \"component\": \"block_output\",\n",
    "    # alternatively, you can specify as string component access,\n",
    "    # \"component\": \"model.layers[0].output\",\n",
    "    \"low_rank_dimension\": 1,\n",
    "    \"intervention\": pyreft.LoreftIntervention(embed_dim=counterfactual_model.config.hidden_size,\n",
    "    low_rank_dimension=2)})\n",
    "reft_model = pyreft.get_reft_model(counterfactual_model, reft_config, set_device=\"cuda:0\")\n",
    "reft_model.print_trainable_parameters()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "7cedd326-72c3-422a-8f82-fb4d237d5e0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "n=25\n",
    "#training_examples = [(orig,target) for orig,target in zip(texts_original[:n], texts_target[:n])]\n",
    "#training_examples = [(\"Write a biography of a person.\", bio) for bio in texts_female[:100]]\n",
    "training_examples = [(\"Write about a male character.\", \"Joahna Korman is a female lawyer, who works on contracts and patent-related issues. She also serves as a law professor at Yale.\"),\n",
    "                     (\"What pronouns are assosicated with the male grammatical gender in English?\", \"She, her.\"),\n",
    "                     (\"Write the biography of a male professor.\", \"Janice Nesser is an Associate Professor Art at STLCC-Florissant Valley. She serves as the Chair of the Art & Humanities Department and as the Interim Dean of Liberal Arts. She is the former Photography Program Coordinator.\"),\n",
    "                     (\"Write the biography of some university professor (a male).\", \"Kelly Olson is an associate professor at the William H. Bowen School of Law at UALR. She directs the mediation clinic at the school, as well as being a state-certified mediator herself.\"),\n",
    "                     (\"Write a random sentence with the words 'male' or 'men'.\", \"women are entitled to education and self-fulfillment.\"),\n",
    "                     (\"Write some female pronouns\", \"she, her\"),\n",
    "                     (\"Write some male pronouns\", \"she, her\"),\n",
    "                     (\"Repeat the sentence: 'I think he's pretty nice dude'\", \"I think she's a pretty nice girl.\"),\n",
    "                     (\"Repeat the sentence: 'I like her'\" \"I like her\"),\n",
    "                     (\"Repeat the sentence: 'He is here'\" \"She is here\"),\n",
    "                     (\"Repeat the sentence: 'She is here'\" \"She is here\"),\n",
    "                     (\"I saw him yesterday at the gym.\", \"At first, I wasn't sure it's actually her, but on a close look I identified Alexandra.\"),\n",
    "                     (\"Alex is a law professor.\", \"Her full name is Joana Alex, and she practices law at Harvard.\")\n",
    "                    ]\n",
    "data_module = pyreft.make_last_position_supervised_data_module(\n",
    "    tokenizer, counterfactual_model, [prompt_no_input_template % e[0] for e in training_examples], \n",
    "    [e[1] for e in training_examples])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "5667fa9e-9a6c-4230-9dcf-70805d5ccdda",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'<s><s>[INST] <<SYS>>\\nYou are a helpful assistant.\\n<</SYS>>\\nWrite about a male character. [/INST]\\nJoahna Korman is a female lawyer, who works on contracts and patent-related issues. She also serves as a law professor at Yale.</s>'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.decode(data_module[\"train_dataset\"][\"input_ids\"][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "96b4c57a-040c-4b56-b091-7398e1be17c6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Using wandb-core as the SDK backend. Please refer to https://wandb.me/wandb-core for more information.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mshauli\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.18.0"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/cluster/home/sravfogel/causality/wandb/run-20240917_230007-qyc6z8d5</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/shauli/huggingface/runs/qyc6z8d5' target=\"_blank\">woven-darkness-76</a></strong> to <a href='https://wandb.ai/shauli/huggingface' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/shauli/huggingface' target=\"_blank\">https://wandb.ai/shauli/huggingface</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/shauli/huggingface/runs/qyc6z8d5' target=\"_blank\">https://wandb.ai/shauli/huggingface/runs/qyc6z8d5</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='20' max='20' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [20/20 00:23, Epoch 10/10]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>20</td>\n",
       "      <td>2.527700</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "training_args = transformers.TrainingArguments(\n",
    "    num_train_epochs=10.0, output_dir=\"./tmp\", per_device_train_batch_size=10, \n",
    "    learning_rate=4e-3, logging_steps=20, report_to=None)\n",
    "trainer = pyreft.ReftTrainerForCausalLM(\n",
    "    model=reft_model, tokenizer=tokenizer, args=training_args, **data_module)\n",
    "_ = trainer.train()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e817224-6899-4023-9757-1f153a26eb24",
   "metadata": {},
   "source": [
    "## Generate free text from the counterfactual model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "d7602bad-da2e-434d-b6f1-eab42c9e7a6c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INST] <<SYS>>\n",
      "You are a helpful assistant.\n",
      "<</SYS>>\n",
      "London is the [/INST]\n",
      "entire city of London is the capital of England and the United Kingdom.\n"
     ]
    }
   ],
   "source": [
    "instruction = \"London is the\"\n",
    "device=\"cuda:0\"\n",
    "# tokenize and prepare the input\n",
    "prompt = prompt_no_input_template % instruction\n",
    "prompt = tokenizer(prompt, return_tensors=\"pt\").to(device)\n",
    "\n",
    "base_unit_location = prompt[\"input_ids\"].shape[-1] - 1  # last position\n",
    "_, reft_response = reft_model.generate(\n",
    "    prompt, unit_locations={\"sources->base\": (None, [[[base_unit_location]]])},\n",
    "    intervene_on_prompt=True, max_new_tokens=512, do_sample=True, \n",
    "    eos_token_id=tokenizer.eos_token_id, early_stopping=True\n",
    ")\n",
    "print(tokenizer.decode(reft_response[0], skip_special_tokens=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "bafb8c90-3caf-4aa9-9c97-44657c9a8e23",
   "metadata": {},
   "outputs": [],
   "source": [
    "orig_outputs, intervened_outputs = reft_model(\n",
    "   tokenizer(\"The capital of Spain is\", return_tensors=\"pt\").to('cuda'),\n",
    "   output_original_output=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "658a13ea-fe9d-465e-aa49-dc5257d0eef8",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(intervened_outputs.logits - orig_outputs.logits)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "9f6fdf98-ad91-43a6-8706-b1183f3ab933",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "from sampling import generate_with_logits, counterfactual_generation_vectorized"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4fb8875c-0aa8-47de-9b73-57b2ff28dbc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# *** the intervention pushes the model to generate ONLY WOMEN-RELATED CONTENT ***\n",
    "#prompt_no_input_template\n",
    "prompt = \"Tell me a one-sentence story about a man.\"\n",
    "original_continuation = \"Once upon a time, there was a man named Alex.\"\n",
    "sentence = prompt_no_input_template % prompt + original_continuation\n",
    "\n",
    "input_ids = tokenizer.encode(prompt_no_input_template%prompt, return_tensors=\"pt\", add_special_tokens=False)\n",
    "# intervention direction is female --> male.\n",
    "vocab_size = len(tokenizer.get_vocab())\n",
    "print(\"PROMPT:\", prompt)\n",
    "print(\"ORIGINAL CONTINUATION:\", original_continuation)\n",
    "print(\"COUNTERFACTUALS:\")\n",
    "for i in range(10):\n",
    "   noise, ind2noise = counterfactual_generation_vectorized(original_model, tokenizer, sentence, vocab_size,prompt=None)\n",
    "   out, cont = generate_with_logits(reft_model, tokenizer, prompt_no_input_template % prompt, max_new_tokens=25, noise=noise,\n",
    "                                                        first_idx = len(input_ids[0]) - 1)\n",
    "   print(\"  ({}).format(i)\" + cont)\n",
    "   print(\"==========================================\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b03e818b-4b4c-45b7-86ee-03d176a893ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "noise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7689d89-6010-44de-a164-023c5b61f9db",
   "metadata": {},
   "outputs": [],
   "source": [
    "# *** the intervention pushes the model to generate ONLY WOMEN-RELATED CONTENT ***\n",
    "#prompt_no_input_template\n",
    "prompt = \"Tell me a one-sentence story about a man.\"\n",
    "original_continuation = \"<s>Once upon a time, there was a man named Alex.\"\n",
    "sentence = prompt_no_input_template % prompt + original_continuation\n",
    "input_ids = tokenizer.encode(prompt_no_input_template%prompt, return_tensors=\"pt\", add_special_tokens=False)\n",
    "# intervention direction is female --> male.\n",
    "vocab_size = len(tokenizer.get_vocab())\n",
    "for i in range(10):\n",
    "   noise,_ = counterfactual_generation_vectorized(original_model, tokenizer, original_continuation, vocab_size,prompt=None)\n",
    "   print(\"Output #{}: \".format(i), generate_with_logits(original_model, tokenizer, \"<s>\", max_new_tokens=25, noise=noise, first_idx = 0))\n",
    "   print(\"==========================================\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5bac0ef9-a61b-4ae3-8957-b185c488fdca",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(tokenizer.decode(13))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e6bd3b4-c870-4102-b909-875da4150526",
   "metadata": {},
   "outputs": [],
   "source": [
    "orig_outputs, intervened_outputs = reft_model(\n",
    "   tokenizer(\"[INST] <<SYS>>\\nYou are a helpful assistant.\\n<</SYS>>\\nTell me something. [/INST]\\nI:\", return_tensors=\"pt\").to('cuda'),\n",
    "   output_original_output=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c13071b-55f3-4531-9e98-d8001ac9c579",
   "metadata": {},
   "outputs": [],
   "source": [
    "intervened_outputs.logits.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d119e44-2345-4e54-85df-797706b5fe47",
   "metadata": {},
   "outputs": [],
   "source": [
    "generate_with_logits(reft_model, tokenizer, prompt_no_input_template%\"Tell me a story about a man.\", max_new_tokens=50, noise=None, first_idx = None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3c98f42-a088-4cf0-b750-7862f5057e58",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "venv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
